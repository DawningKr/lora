{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import lora\n",
    "from lora.nn import Conv2d\n",
    "from lora import LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    total_num = len(y_true)\n",
    "    correct = torch.sum(y_true == y_pred)\n",
    "    return correct / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "epochs = 10\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root=\"./data/\", train=True, transform=ToTensor(), download=True)\n",
    "test_data = CIFAR10(root=\"./data/\", train=False, transform=ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module, LoRA):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, epochs, train_dataloader, loss_fn, optimizer, device):\n",
    "        for epoch in range(epochs):\n",
    "            for X_train, y_train in train_dataloader:\n",
    "                X_train= X_train.type(torch.float32).to(device)\n",
    "                y_train = y_train.to(device)\n",
    "                y_pred = self(X_train)\n",
    "                loss = loss_fn(y_pred, y_train)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "    def eval(self, test_dataloader, loss_fn, accuracy_fn, device):\n",
    "        with torch.inference_mode():\n",
    "            test_loss, test_acc = 0, 0\n",
    "            for X_test, y_test in test_dataloader:\n",
    "                X_test= X_test.type(torch.float32).to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                y_pred = self(X_test)\n",
    "                test_loss += loss_fn(y_pred, y_test)\n",
    "                test_acc += accuracy_fn(y_test, y_pred.argmax(dim=1))\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_acc /= len(test_dataloader)\n",
    "            print(f\"Test Acc: {test_acc} | Test Loss: {test_loss}\")\n",
    "\n",
    "    def get_lora_layers(self):\n",
    "        return [self.conv1, self.conv2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvModel().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.63995760679245 | Test Loss: 1.0225789546966553\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs, train_dataloader, loss_fn, optimizer, device)\n",
    "model.eval(train_dataloader, loss_fn, accuracy, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lora.set_lora_configs_all(model, 8, 1, True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.7079923748970032 | Test Loss: 0.8303349614143372\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs, train_dataloader, loss_fn, optimizer, device)\n",
    "model.eval(train_dataloader, loss_fn, accuracy, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_state = lora.lora_state_dict(model)\n",
    "torch.save(lora_state, \"./data/conv_lora_state.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
